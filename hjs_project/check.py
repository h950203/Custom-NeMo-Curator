import enchant
import re
from typing import List

def is_valid_token(token: str, dictionary) -> bool:
    """
    í† í°ì´ ìœ íš¨í•œ ë‹¨ì–´ì¸ì§€ íŒë³„
    - ìˆ«ìë§Œ: False (123, 456)
    - ë¬¸ì+ìˆ«ì: False (D1, C9, B11)
    - ë‹¨ì¼ ë¬¸ì: False (A, B, C) ë‹¨, a, I ì œì™¸
    - ìˆœìˆ˜ ì•ŒíŒŒë²³: dictionary ì²´í¬
    """
    # ìˆ«ìë§Œ í¬í•¨
    if token.isdigit():
        return False
    
    # ë¬¸ì+ìˆ«ì ë˜ëŠ” ìˆ«ì+ë¬¸ì ì¡°í•©
    if re.search(r'\d', token):
        return False
    
    # ë‹¨ì¼ ë¬¸ì (a, I ì œì™¸)
    if len(token) == 1 and token.lower() not in {'a', 'i'}:
        return False
    
    # ìˆœìˆ˜ ì•ŒíŒŒë²³ì´ë©´ dictionary ì²´í¬
    if token.isalpha():
        return dictionary.check(token)
    
    return False


def filter_txt_file(input_file: str, output_file: str, threshold: float = 0.6):
    """
    txt íŒŒì¼ì—ì„œ ìœ íš¨í•œ ë‹¨ì–´ ë¹„ìœ¨ì´ ë‚®ì€ ë¬¸ì¥ì„ ì œê±°
    
    Args:
        input_file: ì…ë ¥ txt íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ txt íŒŒì¼ ê²½ë¡œ
        threshold: ìœ íš¨í•œ ë‹¨ì–´ ìµœì†Œ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.6 = 60%)
    """
    # PyEnchant ì‚¬ì „ ì´ˆê¸°í™”
    dictionary = enchant.Dict("en_US")
    
    # íŒŒì¼ ì½ê¸°
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    filtered_lines = []
    removed_count = 0
    log_entries = []
    
    print(f"ì´ {len(lines)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì¤‘...")
    print("=" * 80)
    
    for idx, line in enumerate(lines, 1):
        line = line.strip()
        
        # ë¹ˆ ì¤„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        if not line:
            filtered_lines.append(line)
            log_entries.append(f"[ì¤„ {idx}] [ë¹ˆ ì¤„] ìœ ì§€\n")
            continue
        
        # ë‹¨ì–´ í† í°í™” (ëª¨ë“  ë‹¨ì–´ í¬í•¨ - ìˆ«ì+ë¬¸ì ì¡°í•©ë„ í¬í•¨)
        words = re.findall(r'\b\w+\b', line)
        
        # ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ì œê±°
        if len(words) == 0:
            removed_count += 1
            print(f"[ì œê±° {removed_count}] ë‹¨ì–´ ì—†ìŒ: {line[:60]}...")
            log_entries.append(f"[ì¤„ {idx}] [0.0%] (0/0) âŒ ì œê±° - {line}\n")
            continue
        
        # ìœ íš¨í•œ ë‹¨ì–´ ê°œìˆ˜ ì„¸ê¸° (ìƒˆë¡œìš´ ë¡œì§ ì‚¬ìš©)
        valid_count = sum(1 for word in words if is_valid_token(word, dictionary))
        valid_ratio = valid_count / len(words)
        
        # ì„ê³„ê°’ ì´ìƒì´ë©´ ìœ ì§€, ë¯¸ë§Œì´ë©´ ì œê±°
        if valid_ratio >= threshold:
            filtered_lines.append(line)
            log_entries.append(f"[ì¤„ {idx}] [{valid_ratio:.1%}] ({valid_count}/{len(words)}) âœ… ìœ ì§€ - {line}\n")
        else:
            removed_count += 1
            print(f"[ì œê±° {removed_count}] ìœ íš¨ ë‹¨ì–´ ë¹„ìœ¨: {valid_ratio:.1%} ({valid_count}/{len(words)})")
            print(f"  ë¬¸ì¥: {line[:60]}{'...' if len(line) > 60 else ''}")
            log_entries.append(f"[ì¤„ {idx}] [{valid_ratio:.1%}] ({valid_count}/{len(words)}) âŒ ì œê±° - {line}\n")
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in filtered_lines:
            f.write(line + '\n')
    
    # ë¡œê·¸ íŒŒì¼ ì €ì¥
    log_file = output_file.replace('.txt', '_log.txt')
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write(f"íŒŒì¼ í•„í„°ë§ ë¡œê·¸\n")
        f.write(f"ì…ë ¥ íŒŒì¼: {input_file}\n")
        f.write(f"ì¶œë ¥ íŒŒì¼: {output_file}\n")
        f.write(f"ì„ê³„ê°’: {threshold:.0%}\n")
        f.write(f"=" * 80 + "\n\n")
        f.writelines(log_entries)
        f.write(f"\n" + "=" * 80 + "\n")
        f.write(f"ì´ ë¬¸ì¥: {len(lines)}ê°œ\n")
        f.write(f"ìœ ì§€: {len(filtered_lines)}ê°œ\n")
        f.write(f"ì œê±°: {removed_count}ê°œ\n")
    
    print("=" * 80)
    print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"  ì›ë³¸ ë¬¸ì¥: {len(lines)}ê°œ")
    print(f"  ìœ ì§€ëœ ë¬¸ì¥: {len(filtered_lines)}ê°œ")
    print(f"  ì œê±°ëœ ë¬¸ì¥: {removed_count}ê°œ")
    print(f"  ê²°ê³¼ ì €ì¥: {output_file}")
    print(f"  ë¡œê·¸ ì €ì¥: {log_file}")


def analyze_txt_file(input_file: str, threshold: float = 0.6):
    """
    txt íŒŒì¼ ë¶„ì„ (ì €ì¥í•˜ì§€ ì•Šê³  ë¶„ì„ë§Œ)
    
    Args:
        input_file: ì…ë ¥ txt íŒŒì¼ ê²½ë¡œ
        threshold: ìœ íš¨í•œ ë‹¨ì–´ ìµœì†Œ ë¹„ìœ¨
    """
    dictionary = enchant.Dict("en_US")
    
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"\níŒŒì¼ ë¶„ì„: {input_file}")
    print(f"ì„ê³„ê°’: {threshold:.0%} (ì´ìƒë§Œ ìœ ì§€)")
    print("=" * 80)
    
    keep_lines = []
    remove_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # ëª¨ë“  ë‹¨ì–´ í† í° ì¶”ì¶œ (ìˆ«ì+ë¬¸ì ì¡°í•© í¬í•¨)
        words = re.findall(r'\b\w+\b', line)
        if len(words) == 0:
            remove_lines.append((line, 0.0, 0, 0))
            continue
        
        # ìœ íš¨í•œ ë‹¨ì–´ ê°œìˆ˜ ì„¸ê¸°
        valid_count = sum(1 for word in words if is_valid_token(word, dictionary))
        valid_ratio = valid_count / len(words)
        
        if valid_ratio >= threshold:
            keep_lines.append((line, valid_ratio, valid_count, len(words)))
        else:
            remove_lines.append((line, valid_ratio, valid_count, len(words)))
    
    # ìœ ì§€ë  ë¬¸ì¥
    print(f"\nâœ… ìœ ì§€ë  ë¬¸ì¥ ({len(keep_lines)}ê°œ):")
    for i, (line, ratio, valid, total) in enumerate(keep_lines[:5], 1):
        print(f"{i}. [{ratio:.1%}] {line[:60]}{'...' if len(line) > 60 else ''}")
    if len(keep_lines) > 5:
        print(f"   ... ì™¸ {len(keep_lines) - 5}ê°œ")
    
    # ì œê±°ë  ë¬¸ì¥
    print(f"\nâŒ ì œê±°ë  ë¬¸ì¥ ({len(remove_lines)}ê°œ):")
    for i, (line, ratio, valid, total) in enumerate(remove_lines[:5], 1):
        print(f"{i}. [{ratio:.1%}] ({valid}/{total}) {line[:50]}{'...' if len(line) > 50 else ''}")
    if len(remove_lines) > 5:
        print(f"   ... ì™¸ {len(remove_lines) - 5}ê°œ")
    
    print("=" * 80)


if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ íŒŒì¼ëª… ë°›ê¸°
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
        output_file = sys.argv[2] if len(sys.argv) > 2 else "output.txt"
        threshold = float(sys.argv[3]) if len(sys.argv) > 3 else 0.6
    else:
        # ê¸°ë³¸ê°’
        input_file = "input.txt"
        output_file = "output.txt"
        threshold = 0.6
    
    # ì‚¬ìš© ì˜ˆì‹œ 1: ë¶„ì„ë§Œ í•˜ê¸°
    print("ğŸ“Š íŒŒì¼ ë¶„ì„ ëª¨ë“œ")
    try:
        analyze_txt_file(input_file, threshold=threshold)
    except FileNotFoundError:
        print(f"âš  {input_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\ní…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        test_content = """The ship's hull structure includes various plating sections.
L K J Side Bilge Sheerstrake plating H G F E D1 D2 D3 D4 D5
Modern shipbuilding techniques have evolved significantly.
A B C D E F G H I J K L M N O P
Section D1 D2 D3 connects to the main assembly.
This is a completely normal sentence with meaningful content.
X Y Z 123 456 A1 B2 C3
Drawing shows components labeled C1 through C9 with specifications."""
        
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        print(f"âœ… {input_file} íŒŒì¼ ìƒì„± ì™„ë£Œ\n")
        analyze_txt_file(input_file, threshold=threshold)
    
    # ì‚¬ìš© ì˜ˆì‹œ 2: ì‹¤ì œ í•„í„°ë§ ë° ì €ì¥
    print("\n\nğŸ”§ íŒŒì¼ í•„í„°ë§ ë° ì €ì¥")
    try:
        filter_txt_file(input_file, output_file, threshold=threshold)
    except FileNotFoundError:
        print(f"âš  {input_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
