import re
import kss
import html
import unicodedata
from .remove_kaomoji import _remove_kaomoji


class BasePreprocessing:
    """
    A base filter that applies a series of basic text preprocessing steps.
    Used for languages without a specific filter or as a default.
    """
    def __init__(self):
        self._name = "base_preproc"
    
    def apply(self, text: str) -> str:
        if not isinstance(text, str):
            return ""
        # Basic whitespace normalization
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    @property
    def name(self) -> str:
        return self._name

class PersonalFilter:
    """
    A filter that applies a series of personal text preprocessing steps
    to a given text string. This is designed to be used as a modifier
    on a per-sentence basis.
    """
    def __init__(self):
        self._name = "personal_preproc_filter"
    
    def apply(self, text: str) -> str:
        if not isinstance(text, str):
            return ""
        
        # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ì¡°ê¸° ë°˜í™˜
        if not text or text.isspace():
            return ""
        
        # ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (ì „ê°->ë°˜ê° ë³€í™˜ í¬í•¨)
        text = unicodedata.normalize('NFKC', text)
        
        # ë‹¤ì–‘í•œ ìœ ë‹ˆì½”ë“œ ê³µë°± ë¬¸ìë¥¼ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ í†µì¼
        space_chars = '\u00A0\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007\u2008\u2009\u200A\u202F\u205F\u3000'
        for space_char in space_chars:
            text = text.replace(space_char, ' ')
        
        # ì¸ìš© ë¶€í˜¸ ì •ê·œí™”
        text = html.unescape(text)
        
        # ì¸ìš©ë¶€í˜¸ ì¤‘ë³µ ì œê±°
        text = re.sub(r'"+', '"', text)
        text = re.sub(r"'+", "'", text)
        
        # í™€ìˆ˜ ê°œì˜ ì¸ìš©ë¶€í˜¸ ì²˜ë¦¬ (ë§ˆì§€ë§‰ ê²ƒ ì œê±°)
        if text.count('"') % 2 == 1:
            text = text[::-1].replace('"', '', 1)[::-1]
        if text.count("'") % 2 == 1 and text.count("'") > 2:
            text = text[::-1].replace("'", '', 1)[::-1]
        
        # ê´„í˜¸ ì •ê·œí™” ë° ë¶ˆí•„ìš”í•œ ê´„í˜¸ ì œê±°
        # ê´„í˜¸ ë‚´ë¶€ ì•ë’¤ ê³µë°± ì œê±°
        text = re.sub(r'\(\s+', '(', text)
        text = re.sub(r'\s+\)', ')', text)
        text = re.sub(r'\[\s+', '[', text)
        text = re.sub(r'\s+\]', ']', text)
        
        # ë‹¨ì¼ ì•ŒíŒŒë²³ë§Œ í¬í•¨ëœ ê´„í˜¸ ì œê±° (ëª©ë¡ í‘œì‹œ ë“±)
        text = re.sub(r'\(\s*[a-zA-Z]{1}\s*\)', '', text)
        text = re.sub(r'\[\s*[a-zA-Z]{1}\s*\]', '', text)
        
        # ë‹¨ì¼ êµ¬ë‘ì ë§Œ í¬í•¨ëœ ê´„í˜¸ ì œê±°
        text = re.sub(r'\(\s*[;:,.\-!?]\s*\)', '', text)
        text = re.sub(r'\[\s*[;:,.\-!?]\s*\]', '', text)
        
        # ë¶ˆí•„ìš”í•œ ê´„í˜¸ í˜ì–´ ì œê±° : ë¬¸ì¥ì˜ ì œì¼ ì•, ë’¤ê°€ ë¶€í˜¸ë¡œ ë˜ì–´ìˆëŠ” ê²½ìš° ê·¸ ë¶€í˜¸ë¥¼ ì œê±°
        text = text.strip()
        if text.startswith('(') and text.endswith(')') and text.count('(') == 1 and text.count(')') == 1:
            text = text[1:-1].strip()
        if text.startswith('[') and text.endswith(']') and text.count('[') == 1 and text.count(']') == 1:
            text = text[1:-1].strip()
        if text.startswith('"') and text.endswith('"') and text.count('"') == 2:
            text = text[1:-1].strip()
        if text.startswith("'") and text.endswith("'") and text.count("'") == 2:
            text = text[1:-1].strip()
        
        # êµ¬ë‘ì  ì •ê·œí™”
        text = re.sub(r'\.{3,}', 'â€¦', text)
        text = re.sub(r'\,\.', '.', text)
        text = re.sub(r'\.\,', '.', text)
        text = re.sub(r',(\s*,)+', ',', text)
        
        # ì—°ì†ëœ êµ¬ë‘ì  ì •ë¦¬ (!!!, ??? ë“±ì„ !!,?? ë¡œ)
        text = re.sub(r'!{3,}', '!', text)
        text = re.sub(r'\?{3,}', '?', text)
        
        # ë‹¤ì–‘í•œ ì¤‘ê°„ì  ê¸°í˜¸ë¥¼ íšì¼í™”
        text = re.sub(r'\s*[\u318D\u00B7]\s*', 'Â·', text)
        text = re.sub(r'[â€¢ã†ãƒ»á†]', 'Â·', text)
        text = re.sub(' Â· ', 'Â·', text)
        text = re.sub(' Â·', 'Â·', text)
        text = re.sub('Â· ', 'Â·', text)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r' \.(?!\d)', '.', text)  # ë°˜ì  ë’¤ì— ìˆ«ìê°€ ìˆëŠ” ê²½ìš° ê³µë°±ì„ ì—†ì• ì§€ ì•ŠìŒ
        text = re.sub(r' \,', ',', text)
        text = re.sub(r' \;', ';', text)
        text = re.sub(r' \?', '?', text)
        text = re.sub(r' \!', '!', text)
        
        # êµ¬ë‘ì  ì¡°í•© ì˜¤ë¥˜ ìˆ˜ì •
        text = re.sub(r'\.\?', '?', text)
        text = re.sub(r'\,\?', '?', text)
        text = re.sub(r'\.\!', '!', text)
        text = re.sub(r'\,\!', '!', text)
        text = re.sub(r'\.\s+\?', '?', text)
        text = re.sub(r'\.\s+\!', '!', text)
        text = re.sub(r'\,\s+\?', '?', text)
        text = re.sub(r'\,\s+\!', '!', text)
        
        # ì˜¤ìš©ëœ êµ¬ë‘ì  ì œê±°
        text = re.sub(',"', '"', text)
        
        # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ ë¬¸ì ì œê±°
        text = re.sub(r'^\^', '', text)
        text = re.sub(r', \.', '.', text)
        text = re.sub('[â€]', '', text)
        text = re.sub('^[,]', '', text)
        text = re.sub('[,]$', '', text)
        text = re.sub('^[;]', '', text)
        text = re.sub('[;]$', '', text)
        text = re.sub('-{2,}', '-', text)
        
        # ZWS í˜•íƒœì˜ ê³µë°± ì œê±°
        text = re.sub(r'\u200B', '', text)  # ZERO WIDTH SPACE
        text = re.sub(r'\u200C', '', text)  # ZERO WIDTH NON-JOINER
        text = re.sub(r'\u200D', '', text)  # ZERO WIDTH JOINER
        text = re.sub(r'\uFEFF', '', text)  # ZERO WIDTH NO-BREAK SPACE
        text = re.sub(r'\u2060', '', text)  # WORD JOINER
        
        # ê¸°í˜¸ ì œê±°
        patterns = {
            "ë„í˜• ë° í™”ì‚´í‘œ": r'[â€»ã€“â–ªâ™¦]',
            "ìŒì•… ê´€ë ¨ ê¸°í˜¸": r'[â™ªâ™«â™¬â™­â™®â™¯]',
            "ì¹´ë“œ ë° ê²Œì„": r'[â™ â™£â™¥âœªÂ¤]',
            "íŠ¹ìˆ˜ í™”ì‚´í‘œ": r'[á…]',
            "ì´ëª¨ì§€": r'[ğŸ‡]',
            "í•˜ì´í”ˆë¥˜": r'[â€”]',
        }
        for pattern in patterns.values():
            text = re.sub(pattern, '', text)
        
        text = re.sub('â”ƒ', '|', text)
        
        # í•œê¸€ ìëª¨ ë¶„ë¦¬ ë¬¸ì ì œê±°
        text = re.sub(r'[\u1100-\u11FF\u3130-\u318F\uA960-\uA97F\uD7B0-\uD7FF]', '', text)
        
        # ì¹´ì˜¤ëª¨ì§€ ì œê±°
        try:
            text = _remove_kaomoji(text)
        except Exception:
            pass
        
        # ì´ìƒí•œ ê±° ì œê±°
        text = re.sub('[- ]$', '', text)
        text = re.sub('[, ]$', '', text)
        text = re.sub('[ , ]$', '', text)
        text = re.sub(r'[\[\] ]$', '', text)
        text = re.sub('% 1 ', '', text)
        
        # ê³µë°± ì •ê·œí™”
        text = re.sub(r'\s{2,}', ' ', text)
        
        text = text.strip()
        
        # ìµœì¢… ê²€ì¦: ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
        if len(text) < 2 or text in '.,;!?-':
            return ""
        
        return text
    
    @property
    def name(self) -> str:
        return self._name

def custom_normalize_whitespace(text):
    """ê³µë°± ì •ê·œí™”"""
    return re.sub(r'\s+', ' ', text).strip()

def calculate_scores(text, lang, config):
    scores = {}
    lang_config = {**config['defaults'], **config.get(lang, {})}
    
    words = text.split()
    scores['word_count'] = len(words)
    
    total_chars = len(re.sub(r'\s', '', text))
    if total_chars > 0 and 'lang_char_pattern' in lang_config:
        lang_chars = len(re.findall(lang_config['lang_char_pattern'], text))
        scores['lang_ratio'] = lang_chars / total_chars
    else:
        scores['lang_ratio'] = 0
    
    lines = text.split('\n')
    scores['repeated_lines_uniqueness_ratio'] = len(set(lines)) / len(lines) if lines else 0
    
    n = lang_config['ngram_n']
    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]
    scores['repeating_duplicate_ngram_ratio'] = 1 - (len(set(ngrams)) / len(ngrams)) if ngrams else 0
    
    if words:
        scores['symbol_to_word_ratio'] = len(re.findall(r'[^\w\sê°€-í£a-zA-Z]', text)) / len(words)
        scores['urls_ratio'] = len(re.findall(r'https?://\S+', text)) / len(words)
    else:
        scores['symbol_to_word_ratio'] = 0
        scores['urls_ratio'] = 0
    
    weights = config['quality_weights']
    scores['quality_score'] = (
        scores.get('lang_ratio', 0) * weights['lang_ratio'] +
        scores.get('repeated_lines_uniqueness_ratio', 0) * weights['repeated_lines'] +
        (1.0 - scores.get('repeating_duplicate_ngram_ratio', 0)) * weights['repeated_ngrams'] +
        (1.0 - scores.get('symbol_to_word_ratio', 0)) * weights['symbols'] +
        (1.0 - scores.get('urls_ratio', 0)) * weights['urls']
    )
    return scores

def preprocess_text(text, lang, preprocessors):
    """
    Helper to preprocess a single text string using a dictionary of preprocessors.
    """
    if not text or not text.strip():
        return ""
    
    preprocessor = preprocessors.get(lang, BasePreprocessing())
    
    # For Korean, use kss for sentence splitting.
    # For other languages, use a simple split as a fallback.
    if lang == 'ko':
        try:
            sentences = kss.split_sentences(text)
        except Exception:
            # In case of an error with kss, use a simple split.
            sentences = re.split(r'(?<=[.!?])\s+', text)
    else:
        sentences = re.split(r'(?<=[.!?])\s+', text)
    
    # Apply the selected preprocessor to each sentence.
    processed_sentences = [preprocessor.apply(s) for s in sentences]
    
    # Filter out any empty sentences that might result from preprocessing.
    processed_sentences = [s for s in processed_sentences if s]
    
    if not processed_sentences:
        return ""
    
    # Join the processed sentences and normalize whitespace.
    joined_text = " ".join(processed_sentences)
    return custom_normalize_whitespace(joined_text)

def run_filters_on_text(text, lang, config, scores):
    """Check if a processed text passes all filters."""
    lang_config = {**config['defaults'], **config.get(lang, {})}
    
    if not text or not text.strip():
        return False, "preprocessing_empty", "ì „ì²˜ë¦¬ í›„ ë¹ˆ í…ìŠ¤íŠ¸"
    if 'min_words' in lang_config and not (lang_config['min_words'] <= scores['word_count'] <= lang_config['max_words']):
        return False, "word_count", f"ë‹¨ì–´ ìˆ˜: {scores['word_count']}"
    if 'lang_threshold' in lang_config and scores['lang_ratio'] < lang_config['lang_threshold']:
        return False, "language", f"{lang} ë¬¸ì ë¹„ìœ¨: {scores['lang_ratio']:.3f}"
    if (1 - scores['repeated_lines_uniqueness_ratio']) > lang_config['max_repeated_line_fraction']:
        return False, "repeated_lines", f"ë°˜ë³µ ë¼ì¸ ë¹„ìœ¨: {1 - scores['repeated_lines_uniqueness_ratio']:.3f}"
    if scores['repeating_duplicate_ngram_ratio'] > lang_config['max_repeating_ngram_ratio']:
        return False, "repeated_ngrams", f"ë°˜ë³µ N-gram ë¹„ìœ¨: {scores['repeating_duplicate_ngram_ratio']:.3f}"
    if scores['symbol_to_word_ratio'] > lang_config['max_symbol_to_word_ratio']:
        return False, "symbols", f"íŠ¹ìˆ˜ê¸°í˜¸ ë¹„ìœ¨: {scores['symbol_to_word_ratio']:.3f}"
    if scores['urls_ratio'] > lang_config['max_url_ratio']:
        return False, "urls", f"URL ë¹„ìœ¨: {scores['urls_ratio']:.3f}"
    if scores['quality_score'] < lang_config['min_quality_score']:
        return False, "quality_score", f"í’ˆì§ˆ ì ìˆ˜: {scores['quality_score']:.3f}"
    
    return True, "passed", ""