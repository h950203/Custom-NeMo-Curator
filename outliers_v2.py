import pandas as pd
import numpy as np
import os
from pathlib import Path
from sklearn.preprocessing import StandardScaler

def remove_outliers_iqr(df, columns):
    """
    IQR(Interquartile Range) ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì œê±°
    Q1 - 1.5*IQR ë¯¸ë§Œì´ê±°ë‚˜ Q3 + 1.5*IQR ì´ˆê³¼í•˜ëŠ” ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼
    """
    mask = pd.Series([True] * len(df), index=df.index)
    
    outlier_info = {}
    
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        col_mask = (df[col] >= lower_bound) & (df[col] <= upper_bound)
        outliers_count = (~col_mask).sum()
        
        if outliers_count > 0:
            outlier_info[col] = {
                'count': outliers_count,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound
            }
        
        mask &= col_mask
    
    return mask, outlier_info

def normalize_numeric_columns(df, numeric_columns):
    """
    ìˆ«ìí˜• ì—´ì„ í‘œì¤€í™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
    """
    df_normalized = df.copy()
    scaler = StandardScaler()
    
    df_normalized[numeric_columns] = scaler.fit_transform(df[numeric_columns])
    
    return df_normalized

def process_csv_file(file_path):
    """
    CSV íŒŒì¼ì„ ì½ì–´ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ê³  ìƒˆ íŒŒì¼ë¡œ ì €ì¥
    """
    print(f"\n{'='*80}")
    print(f"íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
    print(f"{'='*80}\n")
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(file_path)
    
    print(f"âœ“ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    print(f"  - ì „ì²˜ë¦¬ ì „ í–‰ ìˆ˜: {len(df)}")
    print(f"  - ì „ì²˜ë¦¬ ì „ ì—´ ìˆ˜: {len(df.columns)}")
    
    # ìˆ«ìí˜• ì—´ë§Œ ì„ íƒ
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    print(f"\nâœ“ ìˆ«ìí˜• ì—´ {len(numeric_columns)}ê°œ ê°ì§€:")
    for col in numeric_columns:
        print(f"  - {col}")
    
    if not numeric_columns:
        print("\nâš  ìˆ«ìí˜• ì—´ì´ ì—†ìŠµë‹ˆë‹¤. ì´ìƒì¹˜ ì œê±°ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    # ì´ìƒì¹˜ ì œê±°
    print(f"\n{'='*80}")
    print("ì´ìƒì¹˜ ë¶„ì„ ë° ì œê±° ì¤‘...")
    print(f"{'='*80}\n")
    
    mask, outlier_info = remove_outliers_iqr(df, numeric_columns)
    df_cleaned = df[mask].copy()
    
    # ì´ìƒì¹˜ ì •ë³´ ì¶œë ¥
    if outlier_info:
        print("ğŸ“Š ì—´ë³„ ì´ìƒì¹˜ ì •ë³´:")
        for col, info in outlier_info.items():
            print(f"\n  [{col}]")
            print(f"    - ì´ìƒì¹˜ ê°œìˆ˜: {info['count']}")
            print(f"    - ì •ìƒ ë²”ìœ„: {info['lower_bound']:.2f} ~ {info['upper_bound']:.2f}")
    else:
        print("âœ“ ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì¶œë ¥
    removed_count = len(df) - len(df_cleaned)
    print(f"\n{'='*80}")
    print("ì²˜ë¦¬ ê²°ê³¼:")
    print(f"{'='*80}")
    print(f"  - ì „ì²˜ë¦¬ ì „ í–‰ ìˆ˜: {len(df)}")
    print(f"  - ì „ì²˜ë¦¬ í›„ í–‰ ìˆ˜: {len(df_cleaned)}")
    print(f"  - ì œê±°ëœ í–‰ ìˆ˜: {removed_count} ({removed_count/len(df)*100:.2f}%)")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    file_path_obj = Path(file_path)
    
    # 1. ì´ìƒì¹˜ ì œê±°ëœ íŒŒì¼ ì €ì¥
    removed_file_name = file_path_obj.stem + "_remove_outliers" + file_path_obj.suffix
    removed_file_path = file_path_obj.parent / removed_file_name
    df_cleaned.to_csv(removed_file_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ ì´ìƒì¹˜ ì œê±° íŒŒì¼ ì €ì¥: {removed_file_path}")
    
    # 2. í‘œì¤€í™” ìˆ˜í–‰
    print(f"\n{'='*80}")
    print("í‘œì¤€í™”(Normalization) ìˆ˜í–‰ ì¤‘...")
    print(f"{'='*80}\n")
    
    df_normalized = normalize_numeric_columns(df_cleaned, numeric_columns)
    
    print("âœ“ í‘œì¤€í™” ì™„ë£Œ (í‰ê· =0, í‘œì¤€í¸ì°¨=1)")
    print("\nğŸ“Š í‘œì¤€í™”ëœ ì—´ë³„ í†µê³„:")
    for col in numeric_columns:
        print(f"\n  [{col}]")
        print(f"    - í‰ê· : {df_normalized[col].mean():.6f}")
        print(f"    - í‘œì¤€í¸ì°¨: {df_normalized[col].std():.6f}")
        print(f"    - ìµœì†Œê°’: {df_normalized[col].min():.2f}")
        print(f"    - ìµœëŒ€ê°’: {df_normalized[col].max():.2f}")
    
    # 3. í‘œì¤€í™”ëœ íŒŒì¼ ì €ì¥
    normalized_file_name = file_path_obj.stem + "_normalization" + file_path_obj.suffix
    normalized_file_path = file_path_obj.parent / normalized_file_name
    df_normalized.to_csv(normalized_file_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ í‘œì¤€í™” íŒŒì¼ ì €ì¥: {normalized_file_path}")
    
    print(f"\n{'='*80}")
    print("ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"{'='*80}")
    print(f"\nìƒì„±ëœ íŒŒì¼:")
    print(f"  1. ì´ìƒì¹˜ ì œê±°: {removed_file_path}")
    print(f"  2. í‘œì¤€í™”: {normalized_file_path}")
    print(f"{'='*80}\n")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì…ë ¥
    file_path = input("CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    # ë”°ì˜´í‘œ ì œê±° (ë“œë˜ê·¸ ì•¤ ë“œë¡­ìœ¼ë¡œ ì…ë ¥í•œ ê²½ìš°)
    file_path = file_path.strip('"').strip("'")
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(file_path):
        print(f"\nâŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {file_path}")
    else:
        try:
            process_csv_file(file_path)
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()