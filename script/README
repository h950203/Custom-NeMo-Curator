### 학습용 데이터 만들 때 사용
- best_jsonl_make.py
    - 목적: 기존 JSONL 파일을 특정 형식의 새로운 JSONL 파일로 변환합니다.
    - 작업 내용:
        - 입력된 JSONL 파일을 한 줄씩 읽습니다.
        - 각 줄의 text 필드 값을 가져와서, 미리 정해진 instruction (지시어), src (출발 언어), tgt (목표 언어)와 함께 새로운 JSON 객체를 만듭니다.
        - 원본 text 내용을 새로운 input과 output 필드에 동일하게 채워 넣어, 번역 또는 지시어 기반의 학습 데이터셋 형식으로 변환한 후 새 파일에 저장합니다.

- jsonl_decoder.py
    - 목적: 유니코드(Unicode)로 인코딩된 JSONL 파일을 사람이 읽기 편한 형태로 보거나 변환하는 커맨드 라인 도구입니다.
    - 작업 내용:
        1. 디코딩 모드: \u00e0와 같이 유니코드 이스케이프 시퀀스로 저장된 문자들을 실제 문자(예: 'à')로 변환하여 새로운 _decoded.jsonl 파일을 생성합니다.
        2. 미리보기 모드 (`--preview`): JSONL 파일의 내용을 지정된 줄 수만큼 터미널에 깔끔한 형식으로 출력하여 데이터 구조를 빠르게 확인할 수 있게 해줍니다.

- txt2jsonl.py
    - 목적: 
    - 작업 내용:


### NeMo Curator 거친 후 사용
- script/jsonl_analysis.py
    - 목적: JSONL 파일 내의 숫자형 데이터를 분석하여 다양한 통계 정보를 추출하고 보고서를 생성합니다.
    - 작업 내용:
        - 입력 JSONL 파일을 읽어 각 줄에서 숫자형 데이터를 포함하는 필드를 자동으로 식별하거나, 사용자가 지정한 필드의 숫자 데이터를 추출합니다.
        - 추출된 각 숫자 필드에 대해 데이터 수, 최솟값, 최댓값, 평균, 중앙값, 1사분위수, 3사분위수, 표준편차, 분산 등의 통계량을 계산합니다.
        - 계산된 통계 결과를 콘솔에 상세하게 출력합니다.
        - 사용자의 선택에 따라 분석 결과를 보기 좋게 포맷팅된 텍스트 파일(.txt)로 저장하거나, 시각적으로 정리되고 스타일이 적용된 엑셀 파일(.xlsx)로 저장합니다.
    - 용도: 데이터셋의 숫자형 필드 분포를 빠르게 파악하고, 이상치를 감지하거나, 데이터의 전반적인 특성을 이해하는 데 활용됩니다.

- apply_threshold.py
    - 목적: JSONL 파일에서 특정 숫자 필드(예: 품질 점수)를 기준으로, 주어진 임계값(threshold)에 미치지 못하는 데이터를 필터링(제거)하여 새로운 파일을 생성하는 것입니다.
    - 작업 내용:
        - 사용자로부터 입력 JSONL 파일, 대상 필드 이름(중첩 필드는 점(.)으로 구분), 임계값을 인자로 받습니다.
        - 입력 파일을 한 줄씩 읽어, 각 JSON 객체에서 지정된 필드의 숫자 값을 확인합니다.
        - 해당 값이 사용자가 설정한 임계값보다 크거나 같으면 그 줄을 유지하고, 미만이면 제거합니다.
        - 필터링을 통과한 줄들만 새로운 출력 JSONL 파일에 저장하며, 최종적으로 처리된 줄의 수를 요약하여 보여줍니다.

- organize_jsonl.py
    - 목적: JSONL 파일에서 사용자가 원하는 특정 필드들만 선택적으로 추출하여, 불필요한 정보를 제거한 새로운 JSONL 파일을 생성하는 스크립트입니다.
    - 작업 내용:
        - 사용자로부터 입력 JSONL 파일과 유지할 필드명의 목록을 인자로 받습니다.
        - 기본값으로 'instruction', 'src', 'input', 'tgt', 'output' 필드를 사용하거나, 사용자가 직접 필드 목록을 지정할 수 있습니다.
        - 입력 파일을 한 줄씩 읽어, 각 JSON 객체에서 지정된 필드들만 추출하여 새로운 JSON 객체를 만듭니다.
        - 추출된 데이터만을 담은 새로운 JSONL 파일을 생성하여 저장합니다.


### 최적화 툴 비교할 때 사용
- nlp/syntax_tree.py
    - 목적: 하나의 문장을 여러 자연어 처리(NLP) 라이브러리로 동시에 분석하여 결과를 비교하는 도구입니다.
    - 작업 내용:
        - 사용자로부터 문장과 언어(영어/한국어/일본어)를 입력받습니다.
        - spaCy, Stanza, KoNLPy(한국어), Fugashi(일본어), NLTK(영어) 등 다양한 라이브러리를 사용하여 문장의 의존 관계, 품사, 구문 트리 등을 분석합니다.
        - 각 라이브러리의 분석 결과를 터미널에 출력하고, 모든 결과를 하나의 CSV 파일로 종합하여 results 폴더에 저장합니다. NLP 라이브러리 간 성능이나 분석 차이를 확인할 때 유용합니다.
